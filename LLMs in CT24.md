# LLMs in CT24 dataset

| Partition | Model        | Accuracy | Precision | F1     | Recall |
|-----------|--------------|----------|-----------|--------|--------|
| **Test**  | ⭐Llama-2-7b    | ⭐0.9091 | ⭐0.8202 | ⭐**0.8249** | ⭐0.8295 |
|           | GPT-2        | 0.8622   | 0.7412    | **0.7283** | 0.7159 |
|           | Llama-3.2-1b | 0.8536   | 0.6857    | **0.746**  | 0.8182 |
|           | TinyLlama    | 0.8788   | 0.7979    | **0.7576** | 0.7348|
|           |microsoft/phi2| 0.8827   | 0.8637    | **0.7402** | 0.6477|
| **Dev-Test** | Llama-2-7b    | ⭐0.9151 |⭐ 0.9010 |⭐ **0.8708** |⭐ 0.8426 |
|           | GPT-2        | 0.8742   | 0.8333    | **0.8095** | 0.7870 |
|           | Llama-3.2-1b | 0.8891   | 0.8649    | **0.8603** | 0.8389 |
|           | TinyLlama    |  0.9059  | 0.8956    | **0.8469**  | 0.8179|
|           |microsof/phi2 | 0.8920   | 0.8831    | **0.8130**  | 0.6914|


**Table 4**: Performance of LLMs on Test and Dev-Test
